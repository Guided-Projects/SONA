{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing the libraries\n",
    "from keras.models import Sequential #to initialize the model\n",
    "from keras.layers import Dense  #for hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolution, polling and flattening layers are present in keras.layers package\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPoolingD\n",
    "from keras.layers import Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the model\n",
    "cnn_model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3...)`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# cov2D is the class to add convolution layer to the neural network\n",
    "\n",
    "# add the convolution layer\n",
    "\n",
    "cnn_model.add(Conv2D(32,3,3,input_shape=(64,64,3)))   \n",
    "\n",
    "\n",
    "#parameter 1-no of feature detectors to be applied\n",
    "#parameter 2-shape of the feature detector to be applied \n",
    "#parameter 3-(input_shape) it defines the size of the image and no of channels (color images-3,grey scale images-1)\n",
    "#parameter 4-activation-\"relu\" is added in oder to remove the negative pixels and helps to avoid non linearity of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add pooling layer\n",
    "\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#parameter- pool size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "cnn_model.add(Conv2D(32,3,3))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "cnn_model.add(Conv2D(32,3,3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add flatten layer\n",
    "\n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "#no parameters\n",
    "#flatten layer is the input to the ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=150, kernel_initializer=\"random_uniform\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#full connection\n",
    "#add hidden layer\n",
    "\n",
    "cnn_model.add(Dense(init=\"random_uniform\",activation=\"relu\",output_dim=150))\n",
    "\n",
    "#init is used to define weight initialization strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=3, kernel_initializer=\"random_uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#add output layer\n",
    "cnn_model.add(Dense(init=\"random_uniform\",activation=\"softmax\",output_dim=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the Model\n",
    "# optimizer- Weights updation strategy\n",
    "# binary_crossentropy- Error Calculating strategy\n",
    "# metrics- Model performance calculating strategy\n",
    "\n",
    "cnn_model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "#ImageDataGenerator is the class in keras.preprocessing to appy some preprocessing in the image\n",
    "#(generate new images to the existing images)\n",
    "#it is used to apply some transformations in the image to avoid overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255, # apply feature scaling to get all the values in the range (0 to 1) of the image \n",
    "        shear_range=0.2, # geomentrical operation-moves the image in some particular  direction\n",
    "        zoom_range=0.2, \n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1197 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "    #imagedatagenerator class has the function flow from directiory which helps to import the data and apply transformation stimultaneously\n",
    "    \n",
    "    x_train = train_datagen.flow_from_directory(          \n",
    "        r'C:\\Users\\test01\\Downloads\\animal dataset\\train', #give our file path along with \\training_set\n",
    "        target_size=(64, 64),\n",
    "        batch_size=8,\n",
    "        class_mode='categorical') #class_mode defines the no of classes(2-binary,more than 2 -categorical) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 250 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test = test_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\test01\\Downloads\\animal dataset\\test',   #give our file path along with \\testing_set\n",
    "        target_size=(64, 64),\n",
    "        batch_size=8,\n",
    "        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cow': 0, 'elephant': 1, 'monkey': 2}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.class_indices #to know how the datas are assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/40\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 0.9432 - acc: 0.5402 - val_loss: 0.8986 - val_acc: 0.5484\n",
      "Epoch 2/40\n",
      "150/150 [==============================] - 12s 82ms/step - loss: 0.7382 - acc: 0.6793 - val_loss: 0.6095 - val_acc: 0.7521\n",
      "Epoch 3/40\n",
      "150/150 [==============================] - 12s 83ms/step - loss: 0.6625 - acc: 0.7092 - val_loss: 0.6808 - val_acc: 0.7066\n",
      "Epoch 4/40\n",
      "150/150 [==============================] - 12s 82ms/step - loss: 0.6471 - acc: 0.6990 - val_loss: 0.6058 - val_acc: 0.7479\n",
      "Epoch 5/40\n",
      "150/150 [==============================] - 12s 82ms/step - loss: 0.5723 - acc: 0.7475 - val_loss: 0.5482 - val_acc: 0.7851\n",
      "Epoch 6/40\n",
      "150/150 [==============================] - 12s 81ms/step - loss: 0.5365 - acc: 0.7760 - val_loss: 0.6676 - val_acc: 0.7107\n",
      "Epoch 7/40\n",
      "150/150 [==============================] - 12s 83ms/step - loss: 0.5159 - acc: 0.7853 - val_loss: 0.5401 - val_acc: 0.7810\n",
      "Epoch 8/40\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 0.4727 - acc: 0.7970 - val_loss: 0.6114 - val_acc: 0.7686\n",
      "Epoch 9/40\n",
      "150/150 [==============================] - 12s 83ms/step - loss: 0.4679 - acc: 0.8117 - val_loss: 0.7198 - val_acc: 0.7107\n",
      "Epoch 10/40\n",
      "150/150 [==============================] - 12s 81ms/step - loss: 0.4565 - acc: 0.8060 - val_loss: 0.5044 - val_acc: 0.8182\n",
      "Epoch 11/40\n",
      "150/150 [==============================] - 12s 82ms/step - loss: 0.4209 - acc: 0.8333 - val_loss: 0.5427 - val_acc: 0.7810\n",
      "Epoch 12/40\n",
      "150/150 [==============================] - 12s 83ms/step - loss: 0.3637 - acc: 0.8567 - val_loss: 0.4863 - val_acc: 0.8264\n",
      "Epoch 13/40\n",
      "150/150 [==============================] - 12s 81ms/step - loss: 0.3444 - acc: 0.8567 - val_loss: 0.4845 - val_acc: 0.8140\n",
      "Epoch 14/40\n",
      "150/150 [==============================] - 12s 81ms/step - loss: 0.3429 - acc: 0.8737 - val_loss: 0.5268 - val_acc: 0.8140\n",
      "Epoch 15/40\n",
      "150/150 [==============================] - 12s 81ms/step - loss: 0.3060 - acc: 0.8767 - val_loss: 0.5955 - val_acc: 0.7479\n",
      "Epoch 16/40\n",
      "150/150 [==============================] - 12s 80ms/step - loss: 0.2739 - acc: 0.8857 - val_loss: 0.5999 - val_acc: 0.7479\n",
      "Epoch 17/40\n",
      "150/150 [==============================] - 12s 80ms/step - loss: 0.3217 - acc: 0.8758 - val_loss: 0.6007 - val_acc: 0.7934\n",
      "Epoch 18/40\n",
      "150/150 [==============================] - 12s 82ms/step - loss: 0.2234 - acc: 0.9120 - val_loss: 0.5065 - val_acc: 0.8471\n",
      "Epoch 19/40\n",
      "150/150 [==============================] - 12s 83ms/step - loss: 0.2370 - acc: 0.9053 - val_loss: 0.5672 - val_acc: 0.8017\n",
      "Epoch 20/40\n",
      "150/150 [==============================] - 12s 81ms/step - loss: 0.2028 - acc: 0.9253 - val_loss: 0.5881 - val_acc: 0.8099\n",
      "Epoch 21/40\n",
      "150/150 [==============================] - 12s 81ms/step - loss: 0.2031 - acc: 0.9265 - val_loss: 0.7150 - val_acc: 0.7686\n",
      "Epoch 22/40\n",
      "150/150 [==============================] - 12s 80ms/step - loss: 0.1320 - acc: 0.9483 - val_loss: 0.6811 - val_acc: 0.8099\n",
      "Epoch 23/40\n",
      "150/150 [==============================] - 12s 80ms/step - loss: 0.1372 - acc: 0.9442 - val_loss: 0.5955 - val_acc: 0.8058\n",
      "Epoch 24/40\n",
      "150/150 [==============================] - 12s 81ms/step - loss: 0.2115 - acc: 0.9208 - val_loss: 0.6154 - val_acc: 0.8430\n",
      "Epoch 25/40\n",
      "150/150 [==============================] - 12s 82ms/step - loss: 0.1671 - acc: 0.9433 - val_loss: 0.5926 - val_acc: 0.8471\n",
      "Epoch 26/40\n",
      "150/150 [==============================] - 12s 82ms/step - loss: 0.1265 - acc: 0.9517 - val_loss: 0.5420 - val_acc: 0.8430\n",
      "Epoch 27/40\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 0.0825 - acc: 0.9725 - val_loss: 0.6230 - val_acc: 0.8471\n",
      "Epoch 28/40\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 0.1032 - acc: 0.9650 - val_loss: 0.7186 - val_acc: 0.8099\n",
      "Epoch 29/40\n",
      "150/150 [==============================] - 13s 87ms/step - loss: 0.1207 - acc: 0.9525 - val_loss: 0.7757 - val_acc: 0.8140\n",
      "Epoch 30/40\n",
      "150/150 [==============================] - 12s 83ms/step - loss: 0.1339 - acc: 0.9508 - val_loss: 0.7448 - val_acc: 0.8017\n",
      "Epoch 31/40\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 0.0887 - acc: 0.9658 - val_loss: 0.7654 - val_acc: 0.8223\n",
      "Epoch 32/40\n",
      "150/150 [==============================] - 12s 83ms/step - loss: 0.1251 - acc: 0.9583 - val_loss: 0.7804 - val_acc: 0.8223\n",
      "Epoch 33/40\n",
      "150/150 [==============================] - 12s 83ms/step - loss: 0.1534 - acc: 0.9487 - val_loss: 0.8314 - val_acc: 0.7984\n",
      "Epoch 34/40\n",
      "150/150 [==============================] - 12s 82ms/step - loss: 0.1580 - acc: 0.9450 - val_loss: 0.9160 - val_acc: 0.8058\n",
      "Epoch 35/40\n",
      "150/150 [==============================] - 12s 82ms/step - loss: 0.1235 - acc: 0.9633 - val_loss: 0.7443 - val_acc: 0.8223\n",
      "Epoch 36/40\n",
      "150/150 [==============================] - 12s 80ms/step - loss: 0.0914 - acc: 0.9692 - val_loss: 0.5353 - val_acc: 0.8430\n",
      "Epoch 37/40\n",
      "150/150 [==============================] - 12s 81ms/step - loss: 0.0805 - acc: 0.9708 - val_loss: 0.7801 - val_acc: 0.7851\n",
      "Epoch 38/40\n",
      "150/150 [==============================] - 12s 79ms/step - loss: 0.0898 - acc: 0.9725 - val_loss: 0.8102 - val_acc: 0.8306\n",
      "Epoch 39/40\n",
      "150/150 [==============================] - 12s 83ms/step - loss: 0.0656 - acc: 0.9792 - val_loss: 0.8378 - val_acc: 0.8223\n",
      "Epoch 40/40\n",
      "150/150 [==============================] - 12s 80ms/step - loss: 0.0662 - acc: 0.9792 - val_loss: 1.0487 - val_acc: 0.7727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xe3fea20>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit_generator(\n",
    "        x_train,\n",
    "        steps_per_epoch=150,\n",
    "        epochs=40,\n",
    "        validation_data=x_test,\n",
    "        validation_steps=31)\n",
    "\n",
    "#fit_generator is used to train and test the model simultaneously and gives the accuracy score\n",
    "#(it gives  2 accuracy one is for train and the other is for test)\n",
    "#so we have to provide both train and test data to it \n",
    "# steps_per_epoch-no of training images by batch size\n",
    "#validation_steps-no of testing images by batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save method is used to save the model in .h5 extention\n",
    "cnn_model.save(\"mymodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
